{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1333a7ee",
   "metadata": {},
   "source": [
    "## Data cleaning...\n",
    "*Collect updated music track list and lyrics from web...*\n",
    "    \n",
    "#### Final Features ####\n",
    "*The final dataset is intended to contain the following features for each song acquired...*\n",
    "- song_name \n",
    "- song_artist\n",
    "- song_lyrics\n",
    "- date_added\n",
    "- Spotify Acoustic Features (11 total, ~2 need normalizing)\n",
    "    - energy\n",
    "    - liveness\n",
    "    - tempo\n",
    "    - speechiness\n",
    "    - acousticness\n",
    "    - instrumentalness\n",
    "    - time_signature\n",
    "    - danceability\n",
    "    - duration_ms\n",
    "    - loudness\n",
    "    - valence\n",
    "- Utils for data_mapping (2)\n",
    "    - utils_spotify_id\n",
    "    - utils_genius_data\n",
    "\n",
    "### NOTE: Will need to re-download all song lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c49703ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dayoorigunwa/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/dayoorigunwa/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/dayoorigunwa/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# libraries & tool imports...\n",
    "import os\n",
    "import re\n",
    "import ast\n",
    "import sys\n",
    "import nltk\n",
    "import json\n",
    "import pprint\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from datetime import datetime\n",
    "from spotify import spotifyApi\n",
    "from text_miner import textMiner\n",
    "from text_miner import geniusApi\n",
    "from pandas.io.json import json_normalize  # Packages required for preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import WordNetLemmatizer  # for lemmatization\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01cdb7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing helpers..\n",
    "helper = spotifyApi()\n",
    "txtMiner = textMiner()\n",
    "genius = geniusApi()\n",
    "\n",
    "tools = [helper, txtMiner, genius]\n",
    "# for t in tools:\n",
    "#     print(f\"\\n\\nExisting Methods for: {print(t)} are: \\n {[val for val in list(dir(t)) if str(val)[0] != '_']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "498d6d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>date_added</th>\n",
       "      <th>energy</th>\n",
       "      <th>liveness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>danceability</th>\n",
       "      <th>valence</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>loudness</th>\n",
       "      <th>utils_spotify_id</th>\n",
       "      <th>utils_genius_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>family ties (with Kendrick Lamar)</td>\n",
       "      <td>Baby Keem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-04-21T00:18:15Z</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.230</td>\n",
       "      <td>134.093</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>0.00588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.144</td>\n",
       "      <td>252262.0</td>\n",
       "      <td>-5.453</td>\n",
       "      <td>3QFInJAm9eyaho5vBzxInN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>trademark usa</td>\n",
       "      <td>Baby Keem</td>\n",
       "      <td>[Part I] [Intro] I can't help but feel neglect...</td>\n",
       "      <td>2022-04-21T00:18:29Z</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.274</td>\n",
       "      <td>130.732</td>\n",
       "      <td>0.2810</td>\n",
       "      <td>0.10800</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.067</td>\n",
       "      <td>270671.0</td>\n",
       "      <td>-5.621</td>\n",
       "      <td>6G9aDedv5hYaTgNYDuduqk</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>VALENTINO</td>\n",
       "      <td>24kGoldn</td>\n",
       "      <td>[Chorus] I don't want a valentine,   I just wa...</td>\n",
       "      <td>2022-04-21T00:19:39Z</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.132</td>\n",
       "      <td>150.964</td>\n",
       "      <td>0.1790</td>\n",
       "      <td>0.19900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.523</td>\n",
       "      <td>179133.0</td>\n",
       "      <td>-4.841</td>\n",
       "      <td>6piAUJJQFD8oHDUr0b7l7q</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Pepas</td>\n",
       "      <td>Farruko</td>\n",
       "      <td>[Letra de \"Pepas\"] [Refrán] No me importa lo q...</td>\n",
       "      <td>2022-04-21T00:41:47Z</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.128</td>\n",
       "      <td>130.001</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>0.00776</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.442</td>\n",
       "      <td>287120.0</td>\n",
       "      <td>-3.955</td>\n",
       "      <td>5fwSHlTEWpluwOM0Sxnh5k</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Stick (with JID &amp; J. Cole feat. Kenny Mason &amp; ...</td>\n",
       "      <td>Dreamville</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-04-21T00:42:09Z</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.668</td>\n",
       "      <td>118.574</td>\n",
       "      <td>0.2920</td>\n",
       "      <td>0.26600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.597</td>\n",
       "      <td>309323.0</td>\n",
       "      <td>-5.435</td>\n",
       "      <td>1BzXvBpIFWJgu0P8P6xmP4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               name      artist  \\\n",
       "0           0                  family ties (with Kendrick Lamar)   Baby Keem   \n",
       "1           1                                      trademark usa   Baby Keem   \n",
       "2           2                                          VALENTINO    24kGoldn   \n",
       "3           3                                              Pepas     Farruko   \n",
       "4           4  Stick (with JID & J. Cole feat. Kenny Mason & ...  Dreamville   \n",
       "\n",
       "                                              lyrics            date_added  \\\n",
       "0                                                NaN  2022-04-21T00:18:15Z   \n",
       "1  [Part I] [Intro] I can't help but feel neglect...  2022-04-21T00:18:29Z   \n",
       "2  [Chorus] I don't want a valentine,   I just wa...  2022-04-21T00:19:39Z   \n",
       "3  [Letra de \"Pepas\"] [Refrán] No me importa lo q...  2022-04-21T00:41:47Z   \n",
       "4                                                NaN  2022-04-21T00:42:09Z   \n",
       "\n",
       "   energy  liveness    tempo  speechiness  acousticness  instrumentalness  \\\n",
       "0   0.611     0.230  134.093       0.3300       0.00588          0.000000   \n",
       "1   0.600     0.274  130.732       0.2810       0.10800          0.000002   \n",
       "2   0.717     0.132  150.964       0.1790       0.19900          0.000000   \n",
       "3   0.766     0.128  130.001       0.0343       0.00776          0.000070   \n",
       "4   0.857     0.668  118.574       0.2920       0.26600          0.000000   \n",
       "\n",
       "   time_signature  danceability  valence  duration_ms  loudness  \\\n",
       "0             4.0         0.711    0.144     252262.0    -5.453   \n",
       "1             4.0         0.613    0.067     270671.0    -5.621   \n",
       "2             4.0         0.746    0.523     179133.0    -4.841   \n",
       "3             4.0         0.762    0.442     287120.0    -3.955   \n",
       "4             4.0         0.671    0.597     309323.0    -5.435   \n",
       "\n",
       "         utils_spotify_id utils_genius_data  \n",
       "0  3QFInJAm9eyaho5vBzxInN               NaN  \n",
       "1  6G9aDedv5hYaTgNYDuduqk               NaN  \n",
       "2  6piAUJJQFD8oHDUr0b7l7q               NaN  \n",
       "3  5fwSHlTEWpluwOM0Sxnh5k               NaN  \n",
       "4  1BzXvBpIFWJgu0P8P6xmP4               NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# existing dataset imports... df2 = df.rename({'a': 'X', 'b': 'Y'}, axis=1)\n",
    "data_path = \"/Users/dayoorigunwa/code_base/music_mapping/data/\"\n",
    "allfiles = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "scraped_dfs = [filename for filename in allfiles if \"scraped_dataset\" in filename]\n",
    "scraped_dfs.sort()\n",
    "scraped_df = pd.read_csv(data_path + scraped_dfs[-1])\n",
    "scraped_df.head()\n",
    "# l_v1 = pd.read_csv(data_path + \"cleaned_dataset.csv\")\n",
    "# l_v2 = pd.read_csv(data_path + \"cleaned_dataset_v2.csv\")\n",
    "\n",
    "# print(\n",
    "#     f\"v1 NA count: {l_v1.lyrics.isna().sum()} of {len(l_v1.index)}\\nv2 NA count: {l_v2.lyrics.isna().sum()} of {len(l_v2.index)}\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c055d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 627 entries, 33 to 1070\n",
      "Data columns (total 17 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   name               627 non-null    object \n",
      " 1   artist             627 non-null    object \n",
      " 2   lyrics             627 non-null    object \n",
      " 3   date_added         627 non-null    object \n",
      " 4   energy             627 non-null    float64\n",
      " 5   liveness           627 non-null    float64\n",
      " 6   tempo              627 non-null    float64\n",
      " 7   speechiness        627 non-null    float64\n",
      " 8   acousticness       627 non-null    float64\n",
      " 9   instrumentalness   627 non-null    float64\n",
      " 10  time_signature     627 non-null    float64\n",
      " 11  danceability       627 non-null    float64\n",
      " 12  valence            627 non-null    float64\n",
      " 13  duration_ms        627 non-null    float64\n",
      " 14  loudness           627 non-null    float64\n",
      " 15  utils_spotify_id   627 non-null    object \n",
      " 16  utils_genius_data  627 non-null    object \n",
      "dtypes: float64(11), object(6)\n",
      "memory usage: 88.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# formatting cols...\n",
    "scraped_df.dropna(inplace=True)\n",
    "scraped_df.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "scraped_df[\"utils_genius_data\"] = scraped_df[\"utils_genius_data\"].apply(\n",
    "    lambda x: ast.literal_eval(x)\n",
    ")\n",
    "scraped_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17550b31",
   "metadata": {},
   "source": [
    "#### Defining Lyric Cleaning Methods..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a121bc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Discovery Tools Continued: Text Cleaning...\n",
    "\n",
    "# TOOLS FOR REMOVING SONG STRUCTURE FROM LYRICS...\n",
    "# helper a\n",
    "def get_bracket_idx(lyric_str):\n",
    "    bracket_count = 0\n",
    "    bracket_locs = dict()\n",
    "    for i, char in enumerate(lyric_str):\n",
    "        if char == \"[\":\n",
    "            start_ind = i\n",
    "        elif char == \"]\":\n",
    "            bracket_locs[bracket_count] = (start_ind, i)\n",
    "            bracket_count += 1\n",
    "    return bracket_locs\n",
    "\n",
    "\n",
    "# helper b\n",
    "def extract_brackets(row):\n",
    "    brackets = row[\"flavor_text_idx\"]\n",
    "    lyric_str = row[\"lyrics\"]\n",
    "    bracket_list = []\n",
    "    for key in list(brackets.keys()):\n",
    "        bracket_list.append(lyric_str[brackets[key][0] : brackets[key][1] + 1])\n",
    "    return bracket_list\n",
    "\n",
    "\n",
    "# helper c\n",
    "def scrub_brackets(row):\n",
    "    brackets = row[\"flavor_text\"]\n",
    "    lyric_str = row[\"lyrics\"]\n",
    "    for br in brackets:\n",
    "        lyric_str = lyric_str.replace(br, \"\")\n",
    "    return lyric_str\n",
    "\n",
    "\n",
    "# scrubbing Genius captions from lyrics with helpers a-c...\n",
    "def scrub_song_structure(df, col):\n",
    "    \"\"\"\n",
    "    This function takes in the raw webscraped lyric df and\n",
    "    and a string for column name and returns the df with\n",
    "    the original columns plus a column with the flavor text\n",
    "    indices as flavor_text_idx, a column with the flavor text\n",
    "    as flavor_text, and a column cleaned of its flavor text as lyrics.\n",
    "    \"\"\"\n",
    "    df[\"flavor_text_idx\"] = df[col].apply(lambda x: get_bracket_idx(x))\n",
    "    df[\"flavor_text\"] = df.apply(lambda x: extract_brackets(x), axis=1)\n",
    "    df[\"lyrics\"] = df.apply(lambda x: scrub_brackets(x), axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "# TOOLS FOR PREPPING TEXT DATA FOR NATURAL LANGUAGE PROCESSING...\n",
    "#### Copied methods from: https://medium.com/swlh/nlp-sentiment-analysis-music-to-my-ears-fcf075eaea60\n",
    "## Recall: Definitions of categories: https://medium.com/mlearning-ai/nlp-tokenization-stemming-lemmatization-and-part-of-speech-tagging-9088ac068768\n",
    "def basic_clean(df, col):\n",
    "    \"\"\"\n",
    "    This function takes in a df and a string for a column and\n",
    "    returns the df with a new column named 'basic_clean' with the\n",
    "    passed column text normalized.\n",
    "    \"\"\"\n",
    "    df[\"basic_clean\"] = (\n",
    "        df[col]\n",
    "        .str.lower()\n",
    "        .replace(r\"[^\\w\\s]\", \"\", regex=True)\n",
    "        .str.normalize(\"NFKC\")\n",
    "        .str.encode(\"ascii\", \"ignore\")\n",
    "        .str.decode(\"utf-8\", \"ignore\")\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def tokenize(df, col):\n",
    "    \"\"\"\n",
    "    This function takes in a df and a string for a column and\n",
    "    returns a df with a new column named 'clean_tokes' with the\n",
    "    passed column text tokenized and in a list.\n",
    "    \"\"\"\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    df[\"clean_tokes\"] = df[col].apply(tokenizer.tokenize)\n",
    "    return df\n",
    "\n",
    "\n",
    "def stem(df, col):\n",
    "    \"\"\"\n",
    "    This function takes in a df and a string for a column name and\n",
    "    returns a df with a new column named 'stemmed'.\n",
    "    \"\"\"\n",
    "    # Create porter stemmer\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "\n",
    "    # Stem each token from our clean_tokes Series of lists\n",
    "    stems = df[col].apply(lambda row: [ps.stem(word) for word in row])\n",
    "\n",
    "    # Join our cleaned, stemmed lists of words back into sentences\n",
    "    df[\"stemmed\"] = stems.str.join(\" \")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def lemmatize(df, col):\n",
    "    \"\"\"\n",
    "    This function takes in a df and a string for column name and\n",
    "    returns the original df with a new column called 'lemmatized'.\n",
    "    \"\"\"\n",
    "    # Create the lemmatizer\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "    # Lemmatize each token from our clean_tokes Series of lists\n",
    "    lemmas = df[col].apply(lambda row: [wnl.lemmatize(word) for word in row])\n",
    "\n",
    "    # Join the cleaned and lemmatized tokens back into sentences\n",
    "    df[\"lemmatized\"] = lemmas.str.join(\" \")\n",
    "    return df\n",
    "\n",
    "\n",
    "def remove_stopwords(df, col):\n",
    "    \"\"\"\n",
    "    This function takes in a df and a string for column name and\n",
    "    returns the df with a new column named 'clean' with stopwords removed.\n",
    "    \"\"\"\n",
    "    # Create stopword_list\n",
    "    stopword_list = nltk.corpus.stopwords.words(\"english\")\n",
    "    stopword_list.extend(\"&#9;\")\n",
    "\n",
    "    # Split words in column\n",
    "    words = df[col].str.split()\n",
    "\n",
    "    # Check each word in each row of the column against stopword_list and return only those that are not in list\n",
    "    filtered_words = words.apply(\n",
    "        lambda row: [word for word in row if word not in stopword_list]\n",
    "    )\n",
    "\n",
    "    # Create new column of words that have stopwords removed\n",
    "    df[\"clean_\" + col] = filtered_words.str.join(\" \")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def tag_parts_of_speech(df, col):\n",
    "    \"\"\"\n",
    "    This function takes in a df and a string for column name and\n",
    "    returns the df with a new column named 'pos_tags' with each token\n",
    "    tagged with its respective part of speech .\n",
    "    \"\"\"\n",
    "    df[\"pos_tags\"] = df[col].apply(lambda row: nltk.pos_tag(row))\n",
    "    return df\n",
    "\n",
    "\n",
    "def prep_nlp_data(df, col):\n",
    "    \"\"\"\n",
    "    This function takes in the raw lyric df and\n",
    "    and a string for column name and\n",
    "    returns the df with original columns plus cleaned\n",
    "    and lemmatized content without stopwords.\n",
    "    \"\"\"\n",
    "    # Remove song structure from lyrics\n",
    "    df = scrub_song_structure(df, col)\n",
    "\n",
    "    # Do basic clean on repo content\n",
    "    df = basic_clean(df, col)\n",
    "\n",
    "    # Tokenize clean content\n",
    "    df = tokenize(df, \"basic_clean\")\n",
    "\n",
    "    # Stem cleaned and tokenized content\n",
    "    df = stem(df, \"clean_tokes\")\n",
    "\n",
    "    # Apply Part of Speach tagging to tokenized content\n",
    "    df = lemmatize(df, \"clean_tokes\")\n",
    "\n",
    "    # Lemmatize cleaned and tokenized content\n",
    "    df = tag_parts_of_speech(df, \"clean_tokes\")\n",
    "\n",
    "    # Remove stopwords from Lemmatized content\n",
    "    df = remove_stopwords(df, \"lemmatized\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6a26423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>date_added</th>\n",
       "      <th>energy</th>\n",
       "      <th>liveness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>...</th>\n",
       "      <th>utils_genius_data</th>\n",
       "      <th>flavor_text_idx</th>\n",
       "      <th>flavor_text</th>\n",
       "      <th>basic_clean</th>\n",
       "      <th>clean_tokes</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>clean_lemmatized</th>\n",
       "      <th>song_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Then the Quiet Explosion</td>\n",
       "      <td>Hammock</td>\n",
       "      <td>I can’t feel you There’s no trace Lights will ...</td>\n",
       "      <td>2019-02-14T01:14:15Z</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.0827</td>\n",
       "      <td>95.663</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.894</td>\n",
       "      <td>...</td>\n",
       "      <td>{'annotation_count': 0, 'api_path': '/songs/64...</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>i cant feel you theres no trace lights will bu...</td>\n",
       "      <td>[i, cant, feel, you, theres, no, trace, lights...</td>\n",
       "      <td>i cant feel you there no trace light will burn...</td>\n",
       "      <td>i cant feel you there no trace light will burn...</td>\n",
       "      <td>[(i, NN), (cant, VBP), (feel, NN), (you, PRP),...</td>\n",
       "      <td>cant feel trace light burn blood clay falling ...</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Two Thousand and Seventeen</td>\n",
       "      <td>Four Tet</td>\n",
       "      <td></td>\n",
       "      <td>2019-04-09T15:36:30Z</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.0939</td>\n",
       "      <td>75.495</td>\n",
       "      <td>0.0296</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.161</td>\n",
       "      <td>...</td>\n",
       "      <td>{'annotation_count': 1, 'api_path': '/songs/32...</td>\n",
       "      <td>{0: (0, 19)}</td>\n",
       "      <td>[[Non-Lyrical Vocals]]</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Immunity</td>\n",
       "      <td>Jon Hopkins</td>\n",
       "      <td>You've answered my prayer For a worthless diam...</td>\n",
       "      <td>2019-11-03T13:41:48Z</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.1110</td>\n",
       "      <td>139.878</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.942</td>\n",
       "      <td>...</td>\n",
       "      <td>{'annotation_count': 1, 'api_path': '/songs/57...</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>youve answered my prayer for a worthless diamo...</td>\n",
       "      <td>[youve, answered, my, prayer, for, a, worthles...</td>\n",
       "      <td>youv answer my prayer for a worthless diamond ...</td>\n",
       "      <td>youve answered my prayer for a worthless diamo...</td>\n",
       "      <td>[(youve, RB), (answered, VBN), (my, PRP$), (pr...</td>\n",
       "      <td>youve answered prayer worthless diamond carbon...</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Mumma Don't Tell</td>\n",
       "      <td>Leifur James</td>\n",
       "      <td>My mama don't tell I'm the same My mama don't ...</td>\n",
       "      <td>2020-10-04T19:20:37Z</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>108.028</td>\n",
       "      <td>0.0482</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.762</td>\n",
       "      <td>...</td>\n",
       "      <td>{'annotation_count': 0, 'api_path': '/songs/62...</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>my mama dont tell im the same my mama dont tel...</td>\n",
       "      <td>[my, mama, dont, tell, im, the, same, my, mama...</td>\n",
       "      <td>my mama dont tell im the same my mama dont tel...</td>\n",
       "      <td>my mama dont tell im the same my mama dont tel...</td>\n",
       "      <td>[(my, PRP$), (mama, NN), (dont, NN), (tell, NN...</td>\n",
       "      <td>mama dont tell im mama dont tell fall line mam...</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Quick Musical Doodles</td>\n",
       "      <td>Two Feet</td>\n",
       "      <td>You remember You remember my love You sold yo...</td>\n",
       "      <td>2020-10-04T19:23:11Z</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.3740</td>\n",
       "      <td>169.773</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.685</td>\n",
       "      <td>...</td>\n",
       "      <td>{'annotation_count': 0, 'api_path': '/songs/28...</td>\n",
       "      <td>{0: (0, 8), 1: (100, 108)}</td>\n",
       "      <td>[[Verse 1], [Verse 2]]</td>\n",
       "      <td>you remember you remember my love you sold yo...</td>\n",
       "      <td>[you, remember, you, remember, my, love, you, ...</td>\n",
       "      <td>you rememb you rememb my love you sold your so...</td>\n",
       "      <td>you remember you remember my love you sold you...</td>\n",
       "      <td>[(you, PRP), (remember, VBP), (you, PRP), (rem...</td>\n",
       "      <td>remember remember love sold soul sold soul dru...</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name        artist  \\\n",
       "33    Then the Quiet Explosion       Hammock   \n",
       "38  Two Thousand and Seventeen      Four Tet   \n",
       "39                    Immunity   Jon Hopkins   \n",
       "52            Mumma Don't Tell  Leifur James   \n",
       "53       Quick Musical Doodles      Two Feet   \n",
       "\n",
       "                                               lyrics            date_added  \\\n",
       "33  I can’t feel you There’s no trace Lights will ...  2019-02-14T01:14:15Z   \n",
       "38                                                     2019-04-09T15:36:30Z   \n",
       "39  You've answered my prayer For a worthless diam...  2019-11-03T13:41:48Z   \n",
       "52  My mama don't tell I'm the same My mama don't ...  2020-10-04T19:20:37Z   \n",
       "53   You remember You remember my love You sold yo...  2020-10-04T19:23:11Z   \n",
       "\n",
       "    energy  liveness    tempo  speechiness  acousticness  instrumentalness  \\\n",
       "33   0.357    0.0827   95.663       0.0351         0.652             0.894   \n",
       "38   0.469    0.0939   75.495       0.0296         0.327             0.161   \n",
       "39   0.305    0.1110  139.878       0.0364         0.892             0.942   \n",
       "52   0.283    0.1100  108.028       0.0482         0.345             0.762   \n",
       "53   0.349    0.3740  169.773       0.2700         0.241             0.685   \n",
       "\n",
       "    ...                                  utils_genius_data  \\\n",
       "33  ...  {'annotation_count': 0, 'api_path': '/songs/64...   \n",
       "38  ...  {'annotation_count': 1, 'api_path': '/songs/32...   \n",
       "39  ...  {'annotation_count': 1, 'api_path': '/songs/57...   \n",
       "52  ...  {'annotation_count': 0, 'api_path': '/songs/62...   \n",
       "53  ...  {'annotation_count': 0, 'api_path': '/songs/28...   \n",
       "\n",
       "               flavor_text_idx             flavor_text  \\\n",
       "33                          {}                      []   \n",
       "38                {0: (0, 19)}  [[Non-Lyrical Vocals]]   \n",
       "39                          {}                      []   \n",
       "52                          {}                      []   \n",
       "53  {0: (0, 8), 1: (100, 108)}  [[Verse 1], [Verse 2]]   \n",
       "\n",
       "                                          basic_clean  \\\n",
       "33  i cant feel you theres no trace lights will bu...   \n",
       "38                                                      \n",
       "39  youve answered my prayer for a worthless diamo...   \n",
       "52  my mama dont tell im the same my mama dont tel...   \n",
       "53   you remember you remember my love you sold yo...   \n",
       "\n",
       "                                          clean_tokes  \\\n",
       "33  [i, cant, feel, you, theres, no, trace, lights...   \n",
       "38                                                 []   \n",
       "39  [youve, answered, my, prayer, for, a, worthles...   \n",
       "52  [my, mama, dont, tell, im, the, same, my, mama...   \n",
       "53  [you, remember, you, remember, my, love, you, ...   \n",
       "\n",
       "                                              stemmed  \\\n",
       "33  i cant feel you there no trace light will burn...   \n",
       "38                                                      \n",
       "39  youv answer my prayer for a worthless diamond ...   \n",
       "52  my mama dont tell im the same my mama dont tel...   \n",
       "53  you rememb you rememb my love you sold your so...   \n",
       "\n",
       "                                           lemmatized  \\\n",
       "33  i cant feel you there no trace light will burn...   \n",
       "38                                                      \n",
       "39  youve answered my prayer for a worthless diamo...   \n",
       "52  my mama dont tell im the same my mama dont tel...   \n",
       "53  you remember you remember my love you sold you...   \n",
       "\n",
       "                                             pos_tags  \\\n",
       "33  [(i, NN), (cant, VBP), (feel, NN), (you, PRP),...   \n",
       "38                                                 []   \n",
       "39  [(youve, RB), (answered, VBN), (my, PRP$), (pr...   \n",
       "52  [(my, PRP$), (mama, NN), (dont, NN), (tell, NN...   \n",
       "53  [(you, PRP), (remember, VBP), (you, PRP), (rem...   \n",
       "\n",
       "                                     clean_lemmatized song_length  \n",
       "33  cant feel trace light burn blood clay falling ...         244  \n",
       "38                                                              0  \n",
       "39  youve answered prayer worthless diamond carbon...         386  \n",
       "52  mama dont tell im mama dont tell fall line mam...         336  \n",
       "53  remember remember love sold soul sold soul dru...         183  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New and improved data cleaning...\n",
    "\n",
    "# Cleaning song text...\n",
    "scraped_df = prep_nlp_data(scraped_df, \"lyrics\")\n",
    "\n",
    "# Create a feature that gives us a length of each song...\n",
    "scraped_df[\"song_length\"] = scraped_df[\"lyrics\"].str.len()\n",
    "\n",
    "# Sanity check...\n",
    "scraped_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33165ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop zero-length songs... NO - TODO: Fix webscraping for songs that are missing lyrics!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77f13efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_piece = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "scraped_df.to_csv(data_path + \"prepped_dataset_\" + date_piece + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6792f3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraped_df.lyrics.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6045520",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
